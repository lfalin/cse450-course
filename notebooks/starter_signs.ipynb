{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "starter_signs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA0HPVmIBT4C"
      },
      "source": [
        "# Note: After you run this cell, the training and test data will be available in\n",
        "# the file browser. (Click the folder icon on the left to view it)\n",
        "#\n",
        "# If you don't see the data after the cell completes, click the refresh button\n",
        "# in the file browser (folder icon with circular arrow)\n",
        "\n",
        "# First, let's download and unzip the data\n",
        "!echo \"Downloading files...\"\n",
        "!wget -q https://github.com/lfalin/cse450-course/raw/master/data/roadsigns/training1.zip\n",
        "!wget -q https://github.com/lfalin/cse450-course/raw/master/data/roadsigns/training2.zip\n",
        "!wget -q https://github.com/lfalin/cse450-course/raw/master/data/roadsigns/test.zip\n",
        "!wget -q https://github.com/lfalin/cse450-course/raw/master/data/roadsigns/test_classes.csv\n",
        "\n",
        "!echo \"Unzipping files...\"\n",
        "!unzip -q /content/training1.zip\n",
        "!unzip -q /content/training2.zip\n",
        "!unzip -q /content/test.zip\n",
        "\n",
        "# Combine the two traning directories\n",
        "!echo \"Mergining training data...\"\n",
        "!mkdir /content/training\n",
        "!mv /content/training1/* /content/training\n",
        "!mv /content/training2/* /content/training\n",
        "\n",
        "# Cleanup\n",
        "!echo \"Cleaning up...\"\n",
        "!rmdir /content/training1\n",
        "!rmdir /content/training2\n",
        "!rm training1.zip\n",
        "!rm training2.zip\n",
        "!rm test.zip\n",
        "\n",
        "!echo \"Data ready.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StiU5QcPPxqQ"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALLMN63FPyEQ"
      },
      "source": [
        "# Create an image training dataset\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# We're using keras' image_dataset_from_directory method to load our image data.\n",
        "# See (https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) for details\n",
        "#\n",
        "# A couple of things to note:\n",
        "# 1. We're specifying a number for the seed, so we'll always get the same shuffle and split of our images.\n",
        "# 2. Class names are inferred automatically from the image subdirectory names.\n",
        "# 3. We're splitting the training data into 80% training, 20% validation. \n",
        "\n",
        "\n",
        "training_dir = '/content/training/'\n",
        "image_size = (100, 100)\n",
        "\n",
        "# Split up the training data images into training and validations sets\n",
        "training_data = image_dataset_from_directory(training_dir, validation_split=.2, subset='training', seed=42, image_size=image_size)\n",
        "validation_data = image_dataset_from_directory(training_dir, validation_split=.2, subset='validation', seed=42, image_size=image_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnGBwGVZPyyh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# View first 9 images and their class labels\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in training_data.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(training_data.class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVSfaqgKPzE2"
      },
      "source": [
        "# Build a model..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDc0xuoZs3DK"
      },
      "source": [
        "## Testing the model\n",
        "Once you have built and trained your model, the next step is to run the test images through it and see how well your model does at making predictions for images it has never seen before. \n",
        "\n",
        "Since loading these images and formatting them for the model can be tricky, you may find the following code useful. This code only uses your model to predict the class label for a given image. You'll still need to compare those predictions to the \"ground truth\" class labels in `test_classes.csv` to evaluate how well the model does.\n",
        "\n",
        "    import pathlib\n",
        "    \n",
        "    def predict_an_image(model, file_path):\n",
        "        # Load the image\n",
        "        img = keras.preprocessing.image.load_img(file_path, target_size=(100, 100))\n",
        "    \n",
        "        # Get the image into the shape we need for our network\n",
        "        img_array = keras.preprocessing.image.img_to_array(img)\n",
        "        img_array = tf.expand_dims(img_array, 0) \n",
        "    \n",
        "        # Predict the class\n",
        "        predictions = model.predict(img_array)\n",
        "        score = tf.nn.softmax(predictions[0])\n",
        "        return np.argmax(score)\n",
        "    \n",
        "    # Loop through all images in our test directory and make\n",
        "    # a prediction\n",
        "    testdir = pathlib.Path('/content/test')\n",
        "    image_paths = list(testdir.glob('*.jpg'))\n",
        "    for image_path in image_paths:\n",
        "        prediction = predict_an_image(model, str(image_path))\n",
        "        print(image_path, prediction)\n",
        "  "
      ]
    }
  ]
}